
# alpha vantage api for market data
    # use last x days from date of data?
# how much data? - how many days worth of personal configs?

# (necessary to preprocess data?)
    # (handle missing values, remove duplicates, transform data to suitable format for model)

# split data
    # divide data into training (and validation set?) and test sets
    # training data used to train the model
    # (validation set helps tune hyperparameters)
    # test set used to evaluate final performance

# appropriate ai model
    # regression, classification, clustering???

# scikit-learn, TensorFlow, PyTorth...

# iteratively adjust model parameters to minimize a loss function
# monitor training progress
    # track accuracy, precision, recall...
# use validation and test sets to assess trained model's performance, identify flaws
# adjust hyperparameters, refine data...


